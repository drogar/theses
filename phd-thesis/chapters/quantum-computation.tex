%!TEX root = /Users/gilesb/UofC/thesis/phd-thesis/phd-thesis.tex

\chapter{Quantum computation}\label{chap:quantum_computation}

\section{Linear algebra} % (fold)
\label{sec:linear_algebra}

Quantum computation requires familiarity with the basics of linear algebra. This section will give
definitions of the terms used throughout this thesis.
\subsection{Basic definitions} % (fold)
\label{sub:basic_definitions}


The first definition needed is that of a \emph{vector space}.

\begin{definition}[Vector Space]
  Given a field $F$, whose elements will be referred to as scalars, a \emph{vector space} over $F$
  is a non-empty set $V$ with two operations, \emph{vector addition} and \emph{scalar
  multiplication}. \emph{Vector addition} is defined as ${+}:V\times V \to V$ and denoted as
  $\vc{v}+\vc{w}$ where $\vc{v},\vc{w}\in V$. The set $V$ must be an abelian group under $+$.
  \emph{Scalar multiplication} is defined as ${}:F\times V \to V$ and denoted as $c\vc{v}$ where
  $c\in F, \vc{v} \in V$. Scalar multiplication distributes over both vector addition and scalar
  addition and is associative. $F$'s multiplicative identity is an identity for scalar
  multiplication.

\end{definition}
The specific algebraic requirements are:
\begin{enumerate}
  \item{}$\forall \vc{u},\vc{v},\vc{w} \in V,\ (\vc{u} +\vc{v}) +\vc{w} =
    \vc{u}+ (\vc{v}+\vc{w})$;
  \item{}$\forall \vc{u},\vc{v} \in V,\ \vc{u} +\vc{v} =
    \vc{v}+ \vc{u}$;
  \item{}$\exists  \vc{0} \in V \mathrm{\ such\ that\ } \forall \vc{v} \in V,
    \vc{0} +\vc{v} =  \vc{v}$;
  \item{}$\forall \vc{u} \in V, \exists \vc{v} \in V \mathrm{\ such\ that\ }
    \vc{u}+ \vc{v} = \vc{0}$;
  \item{}$\forall \vc{u},\vc{v} \in V, c\in F,\
    c(\vc{u}+ \vc{v}) = c\vc{u} + c\vc{v}$;
  \item{}$\forall \vc{u} \in V, c,d\in F,\
    (c+d)\vc{u} = c\vc{u} + d\vc{u}$;
  \item{}$\forall \vc{u} \in V, c,d\in F,\
    (c d)\vc{u} = c(d\vc{u})$;
  \item{}$\forall \vc{u} \in V,\
    1\vc{u} = \vc{u}$.
\end{enumerate}

Examples of vector spaces over $F$ are: $F^{n\times m}$ -- the set of $n\times m$ matrices over
$F$; and $F^n$ -- the $n{-}$fold Cartesian product of $F$. $F^{n\times 1}$, the set of $n\times 1$
matrices over $F$ is also called the space of column vectors, while $F^{1\times n}$, the set of row
vectors. Often, $F^n$ is identified with $F^{n\times 1}$.


This thesis  shall identify $F^n$ with the column vector space over $F$.

\begin{definition}[Linearly independent]
  A subset of vectors $\{\vc{v}_i\}$ of the vector space $V$ is said to be \emph{linearly
  independent} when no finite linear combination of them, $\sum a_j\vc{v}_j$ equals \vc{0} unless
  all the $a_j$ are zero.

\end{definition}

\begin{definition}[Basis]
  A \emph{basis} of a vector space $V$ is a linearly independent subset of $V$ that generates $V$.
  That is, any vector $u \in V$ is a linear combination of the basis vectors.
\end{definition}

\begin{definition}\label{def:linear_map_of_vector_spaces}
  Given $V, W$ are vector spaces over $F$ with $v \in V$ and $s \in F$, then
  if $f:V \to W$ is a group homomorphism such that $f(v s) = f(v) s$, then we say $f$ is a
  \emph{linear map}. Furthermore, a map $f:V\times W \to X$ is called \emph{bilinear} when the
  map $f_v:W\to T$ and $f_w:V\to T$ are linear for each $v\in V$ and $w\in W$, where $f_v$ is the
  map obtained from $f$ by fixing $v\in V$ and $f_w$ is obtained from $f$ by fixing  $w\in W$.
\end{definition}

\begin{definition}\label{def:free_vector_space}
  Given a set $S$, the \emph{free vector space} of $S$ over a field $F$ is the abelian group
  of formal sums $\sum a_i s_i$ where the $s_i$ are the elements of $S$ and $a_i \in F$.
  Formal sums are independent of order. Addition is defined as $(\sum a_i s_i) + (\sum b_i s_i)$ is
  $(\sum (a_i + b_i) s_i)$.
\end{definition}

\begin{definition}\label{def:tensor_product_of_vector_spaces}
  Given vector spaces $V, W$ over the base field $F$, consider the free vector space of $V
  \times W = F(V\times W)$. Next, consider the subspace $T$ of $F(V\times W)$ generated by the
  following equations:
  \begin{align*}
    (v_1,w)+(v_2,w) & = (v_1+v_2,w)\\
    (v,w_1)+(v,w_2) & = (v, w_1+w_2)\\
    s(v,w) &= (s v,w)\\
    s(v,w) &= (v,s w),
  \end{align*}
  where $v,v_1,v_2 \in V$, $w,w_1,w_2 \in W$ and $s\in F$. Then the tensor product of
  $V$ and $W$, written $V\*W$ is $F(V\times W)/T$.
\end{definition}

Elements of the tensor product $V\*W$ are written as $v\*w$ and are the $T$-equivalence class of
$(v,w) \in V\times W$. If $\{v_i\}$ is a basis for $V$ and $\{w_j\}$ is a basis for $W$, then the
elements $\{v_i\*w_j\}$ form a basis for $V\*W$.
% subsection basic_definitions (end)
\subsection{Matrices} % (fold)
\label{sub:matrices}


As mentioned above, the set of $n\times m$ matrices over a field is a vector space. Additionally,
matrices compose and the tensor product of matrices is defined.

Matrix composition is defined as usual. That is, for $A = [a_{ij}] \in F^{m\times n}, B =
[b_{jk}]\in F^{n \times p}$:
  \[
    A \, B = \left[\left(\sum_{j}a_{ij}b_{jk}\right)_{ik}\right] \in F^{m \times p}.
  \]



\begin{definition}[Diagonal matrix]
  A \emph{diagonal matrix} is a matrix where the only non-zero entries are those where the column
  index equals the row index.
\end{definition}

The diagonal matrix $n\times n$ with only $1$'s on the diagonal is the identity for matrix
multiplication, and is designated by $I_n$.

\begin{definition}[Transpose]
  The \emph{transpose} of an $n\times m$ matrix $A=[a_{ij}]$ is an $m\times n$ matrix $A^{t}$ with
  the $i,j$ entry being $a_{ji}$.
\end{definition}

When the base field of a matrix is \complex, the complex numbers, the \emph{conjugate transpose}
(also called the \emph{adjoint}) of an $n\times m$ matrix $A=[a_{ij}]$ is defined as the $m\times
n$ matrix $A^{*}$ with the $i,j$ entry being $\overline{a}_{ji}$, where $\overline{a}$ is the
complex conjugate of $a\in\complex$.

When working with column vectors over \complex, note that $\vc{u} \in \complex^n \implies
\vc{u}^{*} \in \complex^{1\times n}$ and that $\vc{u}^{*}\times \vc{u} \in \complex^{1\times 1}$.
This thesis will use the usual identification of \complex{} with $\complex^{1\times1}$. A column
vector \vc{u} is called a \emph{unit vector} when $\vc{u}^{*}\times \vc{u} = 1$.

\begin{definition}[Trace]
  The \emph{trace}, $Tr(A)$ of a square matrix $A=[a_{ij}]$ is $\sum a_{ii}$.
\end{definition}

\subsubsection{Tensor Product} % (fold)
\label{ssub:tensor_product}


The tensor product of two matrices is the usual Kronecker product:
  \[
    U\otimes V =
    \begin{bmatrix}
      u_{11}V&u_{12}V & \cdots &u_{1m}V\\
      u_{21}V&u_{22}V & \cdots &u_{2m}V \\
      \vdots&\vdots&\ddots\\
      u_{n1}V&u_{n2}V & \cdots &u_{nm}V
    \end{bmatrix}
    =
    \begin{bmatrix}
      u_{11}v_{11}&\cdots&u_{12}v_{11} & \cdots& u_{1m}v_{1q} \\
      u_{11}v_{21}&\cdots&u_{12}v_{21} & \cdots& u_{1m}v_{2q} \\
      \vdots&\vdots&\vdots&\ddots \\
      u_{n1}v_{p1}&\cdots&u_{n2}v_{p1} & \cdots& u_{nm}v_{pq} \\
    \end{bmatrix}
  \]
% subsubsection tensor_product (end)

\subsubsection{Special matrices} % (fold)
\label{ssub:special_matrices}

When working with quantum values certain types of matrices over the complex numbers are of special
interest. These are:
\begin{description}
  \item[Unitary Matrix]: Any $n \times n$  matrix $A$ with $A A^{*} = I\ (= A^{*} A)$.
  \item[Hermitian Matrix]: Any  $n \times n$ matrix $A$ with $A=A^{*}$.
  \item[Positive Matrix]: Any Hermitian matrix $A$ in  $\complex^{n\times n}$
    where $\vc{u}^{*} A \vc{u} \ge 0$ for all vectors  $\vc{u}\in \complex^n$. Note
    that for any Hermitian matrix $A$ and vector $u$,  $\vc{u}^{*} A \vc{u}$ is real.
  \item[Completely Positive Matrix]: Any positive matrix $A$ in  $\complex^{n\times n}$
    where $I_m \otimes A$ is positive.
\end{description}
The matrix
  \[
    {\begin{singlespace}
      \begin{bmatrix}
        0&-i\\
        i&0
      \end{bmatrix}
    \end{singlespace}}
  \]
is an example of a matrix that is \emph{unitary}, \emph{Hermitian}, \emph{positive} and
\emph{completely positive}.


% subsubsection special_matrices (end)

\subsubsection{Superoperators} % (fold)
\label{ssub:superoperators}

A \emph{Superoperator} $S$ is a matrix over \complex{} with the following restrictions:
\begin{enumerate}
  \item{} $S$ is \emph{completely positive}. This implies that $S$ is positive as well.
  \item{} For all positive matrices $A$, $Tr(S\,A) \leq Tr(A)$.
\end{enumerate}
% subsubsection superoperators (end)
% subsection matrices (end)

% section linear_algebra (end)


\section{Quantum computation overview} % (fold)
\label{sec:quantum_computation_overview}

Quantum computation proceeds via the application of reversible transformations --- Unitary
transformations.

The semantics of quantum computation can be defined as a $\dagger$-compact closed category as
introduced in \cite{abramsky02:traces,abramsky05:abstracttraces} and completely positive maps as
discussed in \cite{selinger05:dagger}.

\begin{definition}[Dagger Category]
  A \emph{Dagger Category}\cite{selinger05:dagger} is a category \C together with an operation
  $\dagger$ that is an involutive, identity on objects, contra-variant endofunctor on \C.
\end{definition}
Recalling first that a \emph{symmetric monoidal category} is a category \B with a bi-functor $\*$,
an object $I$ and natural isomorphisms:
\begin{align*}
  a_{A,B,C}&: (A\*B)\*C \to A\* (B\*C)\\
  c_{A,B} &:A\*B \to B\*A\\
  ul_A &:A \to I \* A
\end{align*}
with standard coherence conditions, as in \cite{maclan97:categorieswrkmath}. Note that we
also have a map $ur_A: A \to A\*I$ given by $ur_A = ul_A c_{I,A}$ Furthermore, a \emph{compact
closed category} \C is a symmetric monoidal category where each object $A$ has a dual $A^{*}$
together with the maps:
\begin{align*}
  \eta_A:I \to \dual{A} \* A\\
  \epsilon_A : A\*\dual{A} \to I
\end{align*}
such that
\[
  \xymatrix@C+8pt@R-10pt{
    A \ar[r]^{ur_A} \ar@{=}[dddrr]
      & A\* I \ar[r]^(.4){A\*\eta_A}
      & A\* (\dual{A}\*A) \ar[d]^{a^{-1}}\\
    & & (A\*\dual{A})\*A \ar[d]^{\epsilon\*A}\\
    & & I\* A \ar[d]^{ul^{-1}}\\
    & & A
  }
  \quad\text{ and  }\quad
  \xymatrix@C+8pt@R-10pt{
    \dual{A} \ar[r]^{ul_{\dual{A}}} \ar@{=}[dddrr]
      & I\*\dual{A} \ar[r]^(.4){\eta_{\dual{A}\*\dual{A}}}
      & (\dual{A}\*A)\*\dual{A} \ar[d]^{a}\\
    & & \dual{A}\*(A\*\dual{A}) \ar[d]^{\dual{A}\*\epsilon}\\
    & & \dual{A}\*I \ar[d]^{ur^{-1}}\\
    & & A
  }
\]

From the above, we can define a \emph{Dagger symmetric monoidal category} and a \emph{Dagger
compact closed category}. The latter is referred to as a \emph{strongly compact closed category} in
\cite{abramsky02:traces}, where they were initially introduced. In each case, the $\dagger$ functor
is added in a way that retains coherence with the bi-functor $\*$ and with the dualizing operator.
The coherence implies that the $\dgr{i} = i^{-1}$ for the SMC isomorphisms, that $\dgr{(f\*g)} =
\dgr{f}\*\dgr{g}$ for all maps $f,g$ in the symmetric monoidal category and that
\[
  \xymatrix{
    I \ar[dr]_{\eta_A} \ar[r]^{\dgr{\epsilon_A}} & A\* \dual{A} \ar[d]^{c} \\
    &\dual{A}\*A
  }
\]
commutes for all objects $A$ in the compact closed category.


\begin{example}[\rel]
  \rel is a dagger compact closed category with the dual of an object $A$ is $A$, $\*$ is the
  cartesian product and for $R:A\to B$, we have $\dual{R} = \dgr{R} = \{(y,x) | (x,y) \in R\}$.
\end{example}
\begin{example}[\fdh]
  The category of finite dimensional Hilbert spaces, \fdh is a dagger compact closed category with
  the dual of an object $H$ is the normal Hilbert space dual $H^{*}$, the space of continuous
  linear functions from $H$ to the base field. $\*$ is the normal Hilbert space tensor and and for
  $f:A\to B$, we have $\dgr{f}$ is the unique map such that $\langle f x | y \rangle = \langle y |
  \dgr{f}x \rangle$ for all $x\in A$, $y \in B$.
\end{example}

Additionally, if one has a dagger compact closed category with biproducts where the biproducts and
dagger interact such that $\dgr{p_i} = q_i$, this is called a \emph{biproduct dagger compact closed
category}.

In \cite{selinger05:dagger}, the author continues from this point: Starting with a biproduct dagger
compact closed category $\C$, he creates a new category, $\text{CPM}(\C)$ which has the same
objects as $\C$, but morphisms $f:A \to B$ in $\text{CPM}(\C)$ are given by maps $f:\dual{A} \* A
\to \dual{B} \* B$ in $\C$ which are \emph{completely positive}. Note that \rel and \fdh are
biproduct dagger compact closed categories.

From this, the category $\text{CPM}(\C)^{\+}$, the free biproduct completion of $\text{CPM}(\C)$ is
formed, which is suitable for describing quantum computation semantics. For example, given \fdh as
our starting point, the tensor unit $I$ is the field of complex numbers. The type of
$\mathbf{qubit}$ (in \fdh and by lifting, in $\text{CPM}(\fdh)^{\+}$) is given as $I\+I$. At this
stage, the necessity of the CPM construction to model physical reality can be seen in the following
as in \fdh, the morphisms initialization of a qubit: $init:I\+I \to \mathbf{qubit}$ and destructive
measure: $meas: \mathbf{qubit} \to I\+I$ are inverses. However, in $\text{CPM}(\fdh)^{\+}$, these
same maps are given as
\[
  \dual{\mathbf{qubit}} \* \mathbf{qubit} \xrightarrow{meas} I\+
    I \xrightarrow{init}\dual{\mathbf{qubit}} \* \mathbf{qubit}
\]
by the formulae:
\[
  meas
  \begin{pmatrix}
    a & b \\
    c & d
  \end{pmatrix}
  = (a,d), \qquad init(a,d) =
  \begin{pmatrix}
    a &0 \\
    0 & d
  \end{pmatrix}.
\]
Therefore, the maps are not inverses and reflect the physical reality.


\subsection{Density matrix representation}\label{sec:density}
An alternate representation of quantum states, both pure and mixed, is via \emph{density matrices}.
If the state of a system is represented by some column vector $u$, then the matrix $u u^{*}$ is its
density matrix. Note that if $u = \nu v$ for some complex scalar $\nu$ with norm 1, then $u u^{*} =
(\nu v) (\nu v)^{*} = \nu \bar{\nu} v v^{*} = v v^{*} $. For the mixed state $\sum
\nu_{i}\{v_{i}\}$, the density matrix is $\sum \nu_{i}v_{i}v_{i}^{*}$. Density matrices are
positive hermitian matrices with trace $\le 1$. Note that the trace of the density matrix is the
probability the system has reached this particular value in the computation.

The result of applying the unitary transform $U$ to a state $u$ represented by the density matrix
$A$ is $UAU^{*}$. The measurement operation on a density matrix is derived from the measurement
effects on the \qubit. For example, consider the density matrix for $q=\alpha\kz+\beta\ko$,
$\begin{pmatrix}\alpha\bar{\alpha}&\alpha\bar{\beta}\\ \beta\bar{\alpha} &
\beta\bar{\beta}\end{pmatrix}$. Measuring this \qubit gives either
$\begin{pmatrix}\alpha\bar{\alpha}&0\\ 0& 0\end{pmatrix}$ with probability $|\alpha|^{2}$ or
$\begin{pmatrix}0&0\\ 0 & \beta\bar{\beta}\end{pmatrix}$ with probability $|\beta|^{2}$. If the
results of the measurment are not used, this will result in the density matrix
$\begin{pmatrix}\alpha\bar{\alpha}&0\\ 0 & \beta\bar{\beta}\end{pmatrix}$. This extends linearly so
that if a \qubit is measured in the system whose density matrix is \qsmat{A}{B}{C}{D}, the result
will be the mixed density matrix \qsmat{A}{0}{0}{D}.

It is possible to create a complete partial order on density matrices.

\begin{definition}[L\"owner partial order]\label{def:lownerorder}
  For square complex matrices $A,B$ of the same size, define $A \le B$ if $B-A$ is positive.
\end{definition}

\begin{lemma} \label{lemma:cpodensity}
  Designate $D_{n}$ to be the density matrices of size $n\times n$, then the poset $(D_{n}, \le)$
  is a complete partial order.
\end{lemma}
\begin{proof}
  See \cite{selinger04:qpl}, pp 13--14.
\end{proof}

% section quantum_computation_overview (end)
\include{chapters/section/dagger-categories}
\include{chapters/section/quantum-semantics}